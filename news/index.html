<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Changelog • kernelshap</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- dalexverse --><link href="../dalexverse.css" rel="stylesheet"><link href="../dalexverse-2.css" rel="stylesheet"><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Changelog"><meta property="og:image" content="/logo.png"><meta name="robots" content="noindex"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- google analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-5650686-14"></script><script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-5650686-14');
</script></head><body data-spy="scroll" data-target="#toc">
    <div class="container template-news">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html">kernelshap</a>
        <div class="info">
          <span class="partof">part of the <a href="https://github.com/ModelOriented/DrWhy" class="external-link">DrWhy.AI</a>
           developed by the <a href="https://mi2.ai/" class="external-link">MI².AI</a> </span>
          <span class="version version-default">0.6.1</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
        <li>
  <a href="https://github.com/ModelOriented/kernelshap/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
      <h1 data-toc-skip>Changelog <small></small></h1>
      <small>Source: <a href="https://github.com/ModelOriented/kernelshap/blob/main/NEWS.md" class="external-link"><code>NEWS.md</code></a></small>
    </div>

    <div class="section level2">
<h2 class="page-header" data-toc-text="0.6.1" id="kernelshap-061">kernelshap 0.6.1<a class="anchor" aria-label="anchor" href="#kernelshap-061"></a></h2>
<ul><li>
<code>ranger()</code> survival models now also work out-of-the-box without passing a tailored prediction function. Use the new argument <code>survival = "chf"</code> in <code><a href="../reference/kernelshap.html">kernelshap()</a></code> and <code><a href="../reference/permshap.html">permshap()</a></code> to distinguish cumulative hazards (default) and survival probabilities per time point.</li>
</ul></div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.6.0" id="kernelshap-060">kernelshap 0.6.0<small>2024-07-12</small><a class="anchor" aria-label="anchor" href="#kernelshap-060"></a></h2>
<p>This release is intended to be the last before stable version 1.0.0.</p>
<div class="section level3">
<h3 id="major-changes-0-6-0">Major changes<a class="anchor" aria-label="anchor" href="#major-changes-0-6-0"></a></h3>
<ul><li>Factor-valued predictions are not supported anymore.</li>
</ul></div>
<div class="section level3">
<h3 id="maintenance-0-6-0">Maintenance<a class="anchor" aria-label="anchor" href="#maintenance-0-6-0"></a></h3>
<ul><li>Fix CRAN note about unavailable link to <code>gam::gam()</code>.</li>
<li>Added dependency to {MASS} for calculating Moore-Penrose generalized matrix inverse.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.5.0" id="kernelshap-050">kernelshap 0.5.0<small>2024-05-26</small><a class="anchor" aria-label="anchor" href="#kernelshap-050"></a></h2>
<div class="section level3">
<h3 id="new-features-0-5-0">New features<a class="anchor" aria-label="anchor" href="#new-features-0-5-0"></a></h3>
<p>New additive explainer <code><a href="../reference/additive_shap.html">additive_shap()</a></code> that works for models fitted via</p>
<ul><li>
<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code>,</li>
<li>
<code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code>,</li>
<li>
<code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">mgcv::gam()</a></code>,</li>
<li>
<code><a href="https://rdrr.io/pkg/mgcv/man/bam.html" class="external-link">mgcv::bam()</a></code>,</li>
<li>
<code>gam::gam()</code>,</li>
<li>
<code><a href="https://rdrr.io/pkg/survival/man/coxph.html" class="external-link">survival::coxph()</a></code>,</li>
<li>
<code><a href="https://rdrr.io/pkg/survival/man/survreg.html" class="external-link">survival::survreg()</a></code>.</li>
</ul><p>The explainer uses <code>predict(..., type = "terms")</code>, a beautiful trick used in <code>fastshap::explain.lm()</code>. The result will be identical to those returned by <code><a href="../reference/kernelshap.html">kernelshap()</a></code> and <code><a href="../reference/permshap.html">permshap()</a></code> but exponentially faster. Thanks David Watson for the great idea discussed in <a href="https://github.com/ModelOriented/kernelshap/issues/130" class="external-link">#130</a>.</p>
</div>
<div class="section level3">
<h3 id="user-visible-changes-0-5-0">User visible changes<a class="anchor" aria-label="anchor" href="#user-visible-changes-0-5-0"></a></h3>
<ul><li>
<code><a href="../reference/permshap.html">permshap()</a></code> now returns an object of class “kernelshap” to reduce the number of redundant methods.</li>
<li>To distinguish which algorithm has generated the “kernelshap” object, the outputs of <code><a href="../reference/kernelshap.html">kernelshap()</a></code>, <code><a href="../reference/permshap.html">permshap()</a></code> (and <code><a href="../reference/additive_shap.html">additive_shap()</a></code>) got an element “algorithm”.</li>
<li>
<code>is.permshap()</code> has been removed.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.4.2" id="kernelshap-042">kernelshap 0.4.2<a class="anchor" aria-label="anchor" href="#kernelshap-042"></a></h2>
<div class="section level3">
<h3 id="api-0-4-2">API<a class="anchor" aria-label="anchor" href="#api-0-4-2"></a></h3>
<ul><li>{mlr3}: Non-probabilistic classification now works.</li>
<li>{mlr3}: For <em>probabilistic</em> classification, you now have to pass <code>predict_type = "prob"</code>.</li>
</ul></div>
<div class="section level3">
<h3 id="documentation-0-4-2">Documentation<a class="anchor" aria-label="anchor" href="#documentation-0-4-2"></a></h3>
<ul><li>The README has received an {mlr3} and {caret} example.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.4.1" id="kernelshap-041">kernelshap 0.4.1<small>2023-12-03</small><a class="anchor" aria-label="anchor" href="#kernelshap-041"></a></h2>
<div class="section level3">
<h3 id="performance-improvements-0-4-1">Performance improvements<a class="anchor" aria-label="anchor" href="#performance-improvements-0-4-1"></a></h3>
<ul><li>Significant speed-up for pure data.frames, i.e., no data.tables or tibbles.</li>
<li>Some small performance improvements, e.g., for factor predictions and univariate predictions.</li>
<li>Slight speed-up of <code><a href="../reference/permshap.html">permshap()</a></code> by caching calculations for the two special permutations of all 0 and all 1. Consequently, the <code>m_exact</code> component in the output is reduced by 2.</li>
</ul></div>
<div class="section level3">
<h3 id="documentation-0-4-1">Documentation<a class="anchor" aria-label="anchor" href="#documentation-0-4-1"></a></h3>
<ul><li>Rewrote many examples in the README.</li>
<li>Added reference to Erik Strumbelj and Ivan Kononeko (2014).</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.4.0" id="kernelshap-040">kernelshap 0.4.0<small>2023-11-10</small><a class="anchor" aria-label="anchor" href="#kernelshap-040"></a></h2>
<div class="section level3">
<h3 id="major-changes-0-4-0">Major changes<a class="anchor" aria-label="anchor" href="#major-changes-0-4-0"></a></h3>
<ul><li>Added <code><a href="../reference/permshap.html">permshap()</a></code> to calculate exact permutation SHAP values. The function currently works for up to 14 features.</li>
<li>Factor-valued predictions are now supported. Each level is represented by its dummy variable.</li>
</ul></div>
<div class="section level3">
<h3 id="other-changes-0-4-0">Other changes<a class="anchor" aria-label="anchor" href="#other-changes-0-4-0"></a></h3>
<ul><li>Slight speed-up.</li>
<li>Integer valued case weights are now turned into doubles to avoid integer overflow.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.8" id="kernelshap-038">kernelshap 0.3.8<small>2023-09-23</small><a class="anchor" aria-label="anchor" href="#kernelshap-038"></a></h2>
<div class="section level3">
<h3 id="api-improvements-0-3-8">API improvements<a class="anchor" aria-label="anchor" href="#api-improvements-0-3-8"></a></h3>
<ul><li>Multi-output case: column names of predictions are now used as list names of the resulting <code>S</code> and <code>SE</code> lists.</li>
</ul></div>
<div class="section level3">
<h3 id="bug-fixes-0-3-8">Bug fixes<a class="anchor" aria-label="anchor" href="#bug-fixes-0-3-8"></a></h3>
<ul><li>{mlr3} probabilistic classification would not work out-of-the-box. This has been fixed (with corresponding example in the README) in <a href="https://github.com/ModelOriented/kernelshap/pull/100" class="external-link uri">https://github.com/ModelOriented/kernelshap/pull/100</a>
</li>
<li>The progress bar was initialized at 1 instead of 0. This is fixed.</li>
</ul></div>
<div class="section level3">
<h3 id="maintenance-0-3-8">Maintenance<a class="anchor" aria-label="anchor" href="#maintenance-0-3-8"></a></h3>
<ul><li>Added explanation of sampling Kernel SHAP to help file.</li>
<li>In internal calculations, use explicit <code>feature_names</code> as dimnames (<a href="https://github.com/ModelOriented/kernelshap/issues/96" class="external-link uri">https://github.com/ModelOriented/kernelshap/issues/96</a>).</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.7" id="kernelshap-037">kernelshap 0.3.7<small>2023-05-17</small><a class="anchor" aria-label="anchor" href="#kernelshap-037"></a></h2>
<div class="section level3">
<h3 id="maintenance-0-3-7">Maintenance<a class="anchor" aria-label="anchor" href="#maintenance-0-3-7"></a></h3>
<ul><li>Fixed problem in Latex math for MacOS.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.6" id="kernelshap-036">kernelshap 0.3.6<small>2023-05-03</small><a class="anchor" aria-label="anchor" href="#kernelshap-036"></a></h2>
<div class="section level3">
<h3 id="maintenance-0-3-6">Maintenance<a class="anchor" aria-label="anchor" href="#maintenance-0-3-6"></a></h3>
<ul><li>Improved help files and README</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.5" id="kernelshap-035">kernelshap 0.3.5<small>2023-03-31</small><a class="anchor" aria-label="anchor" href="#kernelshap-035"></a></h2>
<div class="section level3">
<h3 id="maintenance-0-3-5">Maintenance<a class="anchor" aria-label="anchor" href="#maintenance-0-3-5"></a></h3>
<ul><li>New contributor: Przemyslaw Biecek - welcome on board!</li>
<li>My new cozy home: <a href="https://github.com/ModelOriented/kernelshap" class="external-link uri">https://github.com/ModelOriented/kernelshap</a>
</li>
<li>Webpage created with “pkgdown”</li>
<li>Introduced Github workflows</li>
<li>More unit tests</li>
</ul></div>
<div class="section level3">
<h3 id="small-visible-changes-0-3-5">Small visible changes<a class="anchor" aria-label="anchor" href="#small-visible-changes-0-3-5"></a></h3>
<ul><li>Removed the <code>ks_extract()</code> function. It was designed to extract objects like the matrix <code>S</code> of SHAP values from the resulting “kernelshap” object <code>x</code>. We feel that the standard extraction options (<code>x$S</code>, <code>x[["S"]]</code>, or <code>getElement(x, "S")</code>) are sufficient.</li>
<li>Adding <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>×</mo><mi>K</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(n \times K)</annotation></semantics></math> matrix of predictions to the output, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> is the number of rows in the explainer data <code>X</code>, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math> is the dimension of a single prediction (usually 1).</li>
<li>Setting <code>verbose = FALSE</code> now does not suppress the warning on too large background data anymore. Use <code><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings()</a></code> instead.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.4" id="kernelshap-034">kernelshap 0.3.4<small>2023-02-26</small><a class="anchor" aria-label="anchor" href="#kernelshap-034"></a></h2>
<div class="section level3">
<h3 id="documentation-0-3-4">Documentation<a class="anchor" aria-label="anchor" href="#documentation-0-3-4"></a></h3>
<ul><li>New logo</li>
<li>Better package description</li>
<li>Better README</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.3" id="kernelshap-033">kernelshap 0.3.3<small>2023-01-11</small><a class="anchor" aria-label="anchor" href="#kernelshap-033"></a></h2>
<div class="section level3">
<h3 id="less-dependencies-0-3-3">Less dependencies<a class="anchor" aria-label="anchor" href="#less-dependencies-0-3-3"></a></h3>
<ul><li>Removed dependency “dorng”. This might have an impact on the seeding if in parallel mode.</li>
<li>Removed dependency “MASS”</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.2" id="kernelshap-032">kernelshap 0.3.2<small>2022-12-17</small><a class="anchor" aria-label="anchor" href="#kernelshap-032"></a></h2>
<div class="section level3">
<h3 id="documentation-0-3-2">Documentation<a class="anchor" aria-label="anchor" href="#documentation-0-3-2"></a></h3>
<ul><li>Rewritten README and examples to better show the role of the background data.</li>
</ul></div>
<div class="section level3">
<h3 id="bug-fixes-0-3-2">Bug fixes<a class="anchor" aria-label="anchor" href="#bug-fixes-0-3-2"></a></h3>
<ul><li>When <code>bg_X</code> contained more columns than <code>X</code>, unflexible prediction functions could fail when being applied to <code>bg_X</code>.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.1" id="kernelshap-031">kernelshap 0.3.1<small>2022-11-18</small><a class="anchor" aria-label="anchor" href="#kernelshap-031"></a></h2>
<div class="section level3">
<h3 id="changes-0-3-1">Changes<a class="anchor" aria-label="anchor" href="#changes-0-3-1"></a></h3>
<ul><li>New argument <code>feature_names</code> allows to specify the features to calculate SHAP values for. The default equals to <code>colnames(X)</code>. This should be changed only in situations when <code>X</code> (the dataset to be explained) contains non-feature columns.</li>
<li>The background dataset can now consist of a single row only. This is useful in situations with natural “off” value such as for image data or for models that can naturally deal with missing values.</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.3.0" id="kernelshap-030">kernelshap 0.3.0<small>2022-09-29</small><a class="anchor" aria-label="anchor" href="#kernelshap-030"></a></h2>
<div class="section level3">
<h3 id="major-improvements-0-3-0">Major improvements<a class="anchor" aria-label="anchor" href="#major-improvements-0-3-0"></a></h3>
<div class="section level4">
<h4 id="exact-calculations-0-3-0">Exact calculations<a class="anchor" aria-label="anchor" href="#exact-calculations-0-3-0"></a></h4>
<p>Thanks to David Watson, exact calculations are now also possible for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">p&gt;5</annotation></semantics></math> features. By default, the algorithm uses exact calculations for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">p \le 8</annotation></semantics></math> and a hybrid strategy otherwise, see the next section. At the same time, the exact algorithm became much more efficient.</p>
<p>A word of caution: Exact calculations mean to create <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>p</mi></msup><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2^p-2</annotation></semantics></math> on-off vectors <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> (cheap step) and evaluating the model on a whopping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mn>2</mn><mi>p</mi></msup><mo>−</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">(2^p-2)N</annotation></semantics></math> rows, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the number of rows of the background data (expensive step). As this explodes with large <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>, we do not recommend the exact strategy for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">p &gt; 10</annotation></semantics></math>.</p>
</div>
<div class="section level4">
<h4 id="hybrid-strategy-0-3-0">Hybrid strategy<a class="anchor" aria-label="anchor" href="#hybrid-strategy-0-3-0"></a></h4>
<p>The iterative Kernel SHAP sampling algorithm of Covert and Lee (2021) [1] works by randomly sample <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> on-off vectors <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> so that their sum follows the SHAP Kernel weight distribution (renormalized to the range from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p-1</annotation></semantics></math>). Based on these vectors, many predictions are formed. Then, Kernel SHAP values are derived as the solution of a constrained linear regression, see [1] for details. This is done multiple times until convergence.</p>
<p>A drawback of this strategy is that many (at least 75%) of the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> vectors will have <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\sum z \in \{1, p-1\}</annotation></semantics></math>, producing many duplicates. Similarly, at least 92% of the mass will be used for the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(p+1)</annotation></semantics></math> possible vectors with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo>,</mo><mi>p</mi><mo>−</mo><mn>2</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\sum z \in \{1, 2, p-1, p-2\}</annotation></semantics></math> etc. This inefficiency can be fixed by a hybrid strategy, combining exact calculations with sampling. The hybrid algorithm has two steps:</p>
<ol style="list-style-type: decimal"><li>Step 1 (exact part): There are <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>p</mi></mrow><annotation encoding="application/x-tex">2p</annotation></semantics></math> different on-off vectors <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\sum z \in \{1, p-1\}</annotation></semantics></math>, covering a large proportion of the Kernel SHAP distribution. The degree 1 hybrid will list those vectors and use them according to their weights in the upcoming calculations. Depending on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>, we can also go a step further to a degree 2 hybrid by adding all <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(p-1)</annotation></semantics></math> vectors with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mi>z</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>2</mn><mo>,</mo><mi>p</mi><mo>−</mo><mn>2</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\sum z \in \{2, p-2\}</annotation></semantics></math> to the process etc. The necessary predictions are obtained along with other calculations similar to those in [1].</li>
<li>Step 2 (sampling part): The remaining weight is filled by sampling vectors <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math> according to Kernel SHAP weights renormalized to the values not yet covered by Step 1. Together with the results from Step 1 - correctly weighted - this now forms a complete iteration as in Covert and Lee (2021). The difference is that most mass is covered by exact calculations. Afterwards, the algorithm iterates until convergence. The output of Step 1 is reused in every iteration, leading to an extremely efficient strategy.</li>
</ol><p>The default behaviour of <code><a href="../reference/kernelshap.html">kernelshap()</a></code> is as follows:</p>
<ul><li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">p \le 8</annotation></semantics></math>: Exact Kernel SHAP (with respect to the background data)</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><mo>≤</mo><mi>p</mi><mo>≤</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">9 \le p \le 16</annotation></semantics></math>: Degree 2 hybrid</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">p &gt; 16</annotation></semantics></math>: Degree 1 hybrid</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p = 1</annotation></semantics></math>: Exact Shapley values</li>
</ul><p>It is also possible to use a pure sampling strategy, see Section “User visible changes” below. While this is usually not advisable compared to a hybrid approach, the options of <code><a href="../reference/kernelshap.html">kernelshap()</a></code> allow to study different properties of Kernel SHAP and doing empirical research on the topic.</p>
<p>Kernel SHAP in the Python implementation “shap” uses a quite similar hybrid strategy, but without iterating. The new logic in the R package thus combines the efficiency of the Python implementation with the convergence monitoring of [1].</p>
<p>[1] Ian Covert and Su-In Lee. Improving KernelSHAP: Practical Shapley Value Estimation Using Linear Regression. Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, PMLR 130:3457-3465, 2021.</p>
</div>
</div>
<div class="section level3">
<h3 id="user-visible-changes-0-3-0">User visible changes<a class="anchor" aria-label="anchor" href="#user-visible-changes-0-3-0"></a></h3>
<ul><li>The default value of <code>m</code> is reduced from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mi>p</mi></mrow><annotation encoding="application/x-tex">8p</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>p</mi></mrow><annotation encoding="application/x-tex">2p</annotation></semantics></math> except when <code>hybrid_degree = 0</code> (pure sampling).</li>
<li>The default value of <code>exact</code> is now <code>TRUE</code> for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">p \le 8</annotation></semantics></math> instead of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≤</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">p \le 5</annotation></semantics></math>.</li>
<li>A new argument <code>hybrid_degree</code> is introduced to control the exact part of the hybrid algorithm. The default is 2 for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>≤</mo><mi>p</mi><mo>≤</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">4 \le p \le 16</annotation></semantics></math> and degree 1 otherwise. Set to 0 to force a pure sampling strategy (not recommended but useful to demonstrate superiority of hybrid approaches).</li>
<li>The default value of <code>tol</code> was reduced from 0.01 to 0.005.</li>
<li>The default of <code>max_iter</code> was reduced from 250 to 100.</li>
<li>The order of some of the arguments behind the first four has been changed.</li>
<li>Paired sampling no longer duplicates <code>m</code>.</li>
<li>Thanks to Mathias Ambuehl, the random sampling of z vectors is now fully vectorized.</li>
<li>The output of <code><a href="https://rdrr.io/r/base/print.html" class="external-link">print()</a></code> is now more slim.</li>
<li>A new <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> function shows more infos.</li>
</ul></div>
<div class="section level3">
<h3 id="other-changes-0-3-0">Other changes<a class="anchor" aria-label="anchor" href="#other-changes-0-3-0"></a></h3>
<ul><li>The resulting object now contains <code>m_exact</code> (the number of on-off vectors used for the exact part), <code>prop_exact</code> (proportion of mass treated in exact fashion), <code>exact</code> flag, and <code>txt</code> (the info message when starting the algorithm).</li>
</ul></div>
<div class="section level3">
<h3 id="bug-fixes-0-3-0">Bug fixes<a class="anchor" aria-label="anchor" href="#bug-fixes-0-3-0"></a></h3>
<ul><li>Predictions of <code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">mgcv::gam()</a></code> would cause an error in <code>check_pred()</code> (they are 1D-arrays).</li>
<li>Fixed small mistakes in the examples of the README (mlr3 and mgcv).</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.2.0" id="kernelshap-020">kernelshap 0.2.0<small>2022-09-05</small><a class="anchor" aria-label="anchor" href="#kernelshap-020"></a></h2>
<div class="section level3">
<h3 id="breaking-change-0-2-0">Breaking change<a class="anchor" aria-label="anchor" href="#breaking-change-0-2-0"></a></h3>
<p>The interface of <code><a href="../reference/kernelshap.html">kernelshap()</a></code> has been revised. Instead of specifying a prediction function, it suffices now to pass the fitted model object. The default <code>pred_fun</code> is now <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">stats::predict</a></code>, which works in most cases. Some other cases are catched via model class (“ranger” and mlr3 “Learner”). The <code>pred_fun</code> can be overwritten by a function of the form <code>function(object, X, ...)</code>. Additional arguments to the prediction function are passed via <code>...</code> of <code><a href="../reference/kernelshap.html">kernelshap()</a></code>.</p>
<p>Some examples:</p>
<ul><li>Logistic regression (logit scale): <code>kernelshap(fit, X, bg_X)</code>
</li>
<li>Logistic regression (probabilities): <code>kernelshap(fit, X, bg_X, type = "response")</code>
</li>
<li>Linear regression with logarithmic response, but evaluated on original scale: Here, the default predict function needs to be overwritten: <code>kernelshap(fit, X, bg_X, pred_fun = function(m, X) exp(predict(m, X)))</code>
</li>
</ul></div>
<div class="section level3">
<h3 id="major-improvements-0-2-0">Major improvements<a class="anchor" aria-label="anchor" href="#major-improvements-0-2-0"></a></h3>
<ul><li>
<code><a href="../reference/kernelshap.html">kernelshap()</a></code> has received a more intuitive interface, see breaking change above.</li>
<li>The package now supports multidimensional predictions. Hurray!</li>
<li>Thanks to David Watson, parallel computing is now supported. The user needs to set up the parallel backend before calling <code><a href="../reference/kernelshap.html">kernelshap()</a></code>, e.g., using the “doFuture” package, and then set <code>parallel = TRUE</code>. Especially on Windows, sometimes not all global variables or packages are loaded in the parallel instances. These can be specified by <code>parallel_args</code>, a list of arguments passed to <code><a href="https://rdrr.io/pkg/foreach/man/foreach.html" class="external-link">foreach()</a></code>.</li>
<li>Even without parallel computing, <code><a href="../reference/kernelshap.html">kernelshap()</a></code> has become much faster.</li>
<li>For <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>≤</mo><mi>p</mi><mo>≤</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">2 \le p \le 5</annotation></semantics></math> features, the algorithm now returns exact Kernel SHAP values with respect to the given background data. (For <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p = 1</annotation></semantics></math>, exact <em>Shapley values</em> are returned.)</li>
<li>Direct handling of “tidymodels” models.</li>
</ul></div>
<div class="section level3">
<h3 id="user-visible-changes-0-2-0">User visible changes<a class="anchor" aria-label="anchor" href="#user-visible-changes-0-2-0"></a></h3>
<ul><li>Besides <code>matrix</code>, <code>data.frame</code>s, and <code>tibble</code>s, the package now also accepts <code>data.table</code>s (if the prediction function can deal with them).</li>
<li>
<code><a href="../reference/kernelshap.html">kernelshap()</a></code> is less picky regarding the output structure of <code>pred_fun()</code>.</li>
<li>
<code><a href="../reference/kernelshap.html">kernelshap()</a></code> is less picky about the column structure of the background data <code>bg_X</code>. It should simply contain the columns of <code>X</code> (but can have more or in different order). The old behaviour was to launch an error if <code>colnames(X) != colnames(bg_X)</code>.</li>
<li>The default <code>m = "auto"</code> has been changed from <code>trunc(20 * sqrt(p))</code> to <code>max(trunc(20 * sqrt(p)), 5 * p</code>. This will have an effect for cases where the number of features <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">p &gt; 16</annotation></semantics></math>. The change will imply more robust results for large p.</li>
<li>There were too many “ks_*()” functions to extract elements of a “kernelshap” object. They are now all deprecated and replaced by <code>ks_extract(, what = "S")</code>.</li>
<li>Added “MASS”, “doRNG”, and “foreach” to dependencies.</li>
</ul></div>
<div class="section level3">
<h3 id="bug-fixes-0-2-0">Bug fixes<a class="anchor" aria-label="anchor" href="#bug-fixes-0-2-0"></a></h3>
<ul><li>Depending on <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>, the matrix inversion required in the constrained least-squares solution could fail. It is now replaced by <code><a href="https://rdrr.io/pkg/MASS/man/ginv.html" class="external-link">MASS::ginv()</a></code>, the Moore-Penrose pseudoinverse using <code><a href="https://rdrr.io/r/base/svd.html" class="external-link">svd()</a></code>.</li>
</ul></div>
<div class="section level3">
<h3 id="new-contributor-0-2-0">New contributor<a class="anchor" aria-label="anchor" href="#new-contributor-0-2-0"></a></h3>
<ul><li>David Watson</li>
</ul></div>
</div>
    <div class="section level2">
<h2 class="page-header" data-toc-text="0.1.0" id="kernelshap-010">kernelshap 0.1.0<small>2022-08-12</small><a class="anchor" aria-label="anchor" href="#kernelshap-010"></a></h2>
<p>This is the initial release.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>

</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Michael Mayer, David Watson.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

      </footer></div>




  </body></html>

